<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tianyuan (Roger) Dai</title>

    <meta name="author" content="Roger">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="width:63%;vertical-align:middle">
                <p class="name" style="text-align: center">
                  Tianyuan Dai
                </p>
                <p>I'm a Master's student in Computer Science at Stanford University, affiliated with the <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab</a> and <a href="http://pair.stanford.edu/">Stanford PAIR Group</a>. 
                  I have the privilege of conducting cutting-edge research in embodied AI and robotic learning, advised by Prof. <a href="https://engineering.stanford.edu/people/fei-fei-li/">Fei-Fei Li</a>. 
                  Previously, I obtained a Bachelor's degree in Computer Science and Mathematics at the Hong Kong University of Science and Technology (HKUST), where I worked on 3D and multimodal generation, advised by Prof. <a href="https://cse.hkust.edu.hk/admin/people/faculty/profile/cktang">Chi-Keung Tang</a> and Prof. <a href="https://yuwingtai.github.io/">Yu-Wing Tai</a>.
                </p>
                <p>
                  Special thanks to Prof. <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a>, whose talk at HKUST in my final undergraduate semester inspired me to transition from computer vision to embodied AI. I am also deeply grateful to <a href="https://jdw.ong/">Josiah Wong</a>, <a href="https://yunfanj.com/">Yunfan Jiang</a>, <a href="https://www.chenwangjeremy.net/">Chen Wang</a>, and <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a> for their invaluable advice on my research projects at Stanford.
                </p>
                <p style="text-align:center">
                  <a href="mailto:tydai@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=pUuRNGUAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/tianyuandai">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:25%;max-width:30%">
                <a href="images/profile.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody>
      </tr>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="width:100%;vertical-align:middle">
            <h2>Research</h2>
            <p>
              My long-term vision is to integrate human-level understanding of real-world environments into robotics algorithms that assist people with daily tasks using data-driven approaches. 
              I am passionate about both designing reliable robotic systems and developing innovative algorithms that enable more robust policies. 
              Recently, my focus has been on developing <strong>real-to-sim-to-real</strong> paradigms for robust manipulation policy learning.
            </p>
          </td>
        </tr>
      </tbody>
    </table>

    <br>
    <br>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="width:100%;vertical-align:middle">
            <h2>News</h2>
            <ul style="list-style-type: disc">
              <li>[2024.09] <a href="https://openreview.net/forum?id=7c5rAY8oU3">ACDC</a> accepted to CoRL 2024.</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>

    <br>
    <br>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="width:100%;vertical-align:middle">
            <h2>Publications</h2>
            <p>
              * Equal Contribution
            </p>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="width:30%;vertical-align:middle;padding-right:20px;padding-bottom:20px">
            <div class="one">
              <div class="two" id='FaceDNeRF_video'>
                <video width="100%" height="auto" muted autoplay loop>
                  <source src="images/Cover-FaceDNeRF.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </td>
          <td style="width:70%;vertical-align:middle;padding-bottom:20px">
            <a href="https://github.com/BillyXYB/FaceDNeRF">
              <span class="papertitle">FaceDNeRF: Semantics-Driven Face Reconstruction, Prompt Editing and Relighting with Diffusion Models</span>
            </a>
            <br>
            <a href="https://zhang1023.github.io/ZHANG_Hao.github.io/">Hao Zhang</a>*,
            <a href="https://yanbo-xu.netlify.app/">Yanbo Xu</a>*,
        <strong>Tianyuan Dai</strong>*,
            <a href="https://yuwingtai.github.io/">Yu-Wing Tai</a>,
            <a href="https://cse.hkust.edu.hk/admin/people/faculty/profile/cktang">Chi-Keung Tang</a>
            <br>
            <em>NeurIPS</em>, 2023
            <br>
            <a href="https://github.com/BillyXYB/FaceDNeRF">project page</a>
            /
            <a href="https://www.youtube.com/watch?v=paxqlzW7z1Q">video</a>
            /
            <a href="https://arxiv.org/abs/2306.00783">arXiv</a>
          </td>
        </tr>

        <tr>
          <td style="width:30%;vertical-align:middle;padding-right:20px;padding-bottom:20px">
            <div class="one">
              <div class="two" id='FLNeRF_video'>
                <video width="100%" height="auto" muted autoplay loop>
                  <source src="images/Cover-FLNeRF.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </td>
          <td style="width:70%;vertical-align:middle;padding-bottom:20px">
            <a href="https://arxiv.org/abs/2211.11202">
              <span class="papertitle">FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields</span>
            </a>
            <br>
            <a href="https://zhang1023.github.io/ZHANG_Hao.github.io/">Hao Zhang</a>*,
        <strong>Tianyuan Dai</strong>*,
            <a href="https://yuwingtai.github.io/">Yu-Wing Tai</a>,
            <a href="https://cse.hkust.edu.hk/admin/people/faculty/profile/cktang">Chi-Keung Tang</a>
            <br>
            <em>Champion, IEEE (Hong Kong) Computational Intelligence Chapter Final Year Project Competition</em>, 2022-2023
            <br>
            <a href="https://github.com/ZHANG1023/FLNeRF">video</a>
            /
            <a href="https://arxiv.org/abs/2211.11202">arXiv</a>
          </td>
        </tr>
      </tbody>
    </table>

    <br>
    <br>
          
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td>
            <h2>Teaching</h2>
          </td>
        </tr>
      </tbody>
    </table>

    <br>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="width:30%;vertical-align:middle;padding-right:20px;padding-bottom:20px">
            <div class="one">
              <div class="two" id='231a-cover-img'>
                <img src="images/231A-cover.png" width="100%">
              </div>
            </div>
          </td>
          <td style="width:70%;vertical-align:middle;padding-bottom:20px">
            <a href="https://web.stanford.edu/class/cs231a/">
              <span class="papertitle">Stanford CS231A Computer Vision, From 3D Perception to 3D Reconstruction and beyond</span>
            </a>
            <br>
            Spring 2024
            <br>
            Teaching Assistant
            <br>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              <a href="https://github.com/jonbarron/jonbarron_website">Website Template</a>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
