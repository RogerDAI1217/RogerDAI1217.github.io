<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tianyuan (Roger) Dai</title>

    <meta name="author" content="Roger">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Roger
                </p>
                <p>I'm a Master's student in Computer Science at Stanford University, affiliated with the <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab</a>. 
                  I have the privilege of conducting cutting-edge research in embodied AI and robotic learning, advised by Prof. <a href="https://engineering.stanford.edu/people/fei-fei-li/">Fei-Fei Li</a>. 
                  Previously, I obtained a Bachelor's degree in Computer Science and Mathematics at the Hong Kong University of Science and Technology (HKUST), where I worked on 3D and multimodal generation, advised by Prof. <a href="https://cse.hkust.edu.hk/admin/people/faculty/profile/cktang">Chi-Keung Tang</a> and Prof. <a href="https://yuwingtai.github.io/">Yu-Wing Tai</a>.
                </p>
                <p>
                  Special thanks to Prof. <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a>, whose talk at HKUST in my final undergraduate semester inspired me to transition from computer vision to embodied AI. I am also deeply grateful to <a href="https://jdw.ong/">Josiah Wong</a>, <a href="https://yunfanj.com/">Yunfan Jiang</a>, <a href="https://www.chenwangjeremy.net/">Chen Wang</a>, and <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a> for their invaluable advice on my research projects at Stanford.
                </p>
                <p style="text-align:center">
                  <a href="mailto:tydai@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=pUuRNGUAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="www.linkedin.com/in/tianyuandai">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody>
      </tr>
    </table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Research</h2>
            <p>
              My long-term goal is to embed human-level understanding of real world environments into robotics algorithms that can help human with daily activities using data-driven methods. 
              I am interested in both building reliable robotics systems, and developing novel algorithms for more robust policies.
              I am recently working on the real-to-sim-to-real paradigmn for robust manipulation policy learning.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='FaceDNeRF_cover'>
                <img src="Cover-FaceDNeRF.gif" style="width:100%;">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/BillyXYB/FaceDNeRF">
              <span class="papertitle">FaceDNeRF: Semantics-Driven Face Reconstruction, Prompt Editing and Relighting with Diffusion Models</span>
            </a>
            <br>
            <a href="https://zhang1023.github.io/ZHANG_Hao.github.io/">Hao Zhang</a>*,
            <a href="https://yanbo-xu.netlify.app/">Yanbo Xu</a>*,
        <strong>Tianyuan Dai</strong>*,
            <a href="https://bmild.github.io/">Yu-Wing Tai</a>
            <a href="https://bmild.github.io/">Chi-Keung Tang</a>
            <br>
            <em>NeurIPS</em>, 2023
            <br>
            <a href="https://github.com/BillyXYB/FaceDNeRF">project page</a>
            /
            <a href="https://www.youtube.com/watch?v=paxqlzW7z1Q">video</a>
            /
            <a href="https://arxiv.org/abs/2306.00783">arXiv</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='FLNeRF_cover'>
                <img src="Cover-FLNeRF.gif" style="width:100%;">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2211.11202">
              <span class="papertitle">FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields</span>
            </a>
            <br>
            <a href="https://zhang1023.github.io/ZHANG_Hao.github.io/">Hao Zhang</a>*,
            <a href="https://yanbo-xu.netlify.app/">Yanbo Xu</a>*,
        <strong>Tianyuan Dai</strong>*,
            <a href="https://yuwingtai.github.io/">Yu-Wing Tai</a>
            <a href="https://cse.hkust.edu.hk/admin/people/faculty/profile/cktang">Chi-Keung Tang</a>
            <br>
            <em>Champion, IEEE (Hong Kong) Computational Intelligence Chapter Final Year Project Competition</em>, 2022-2023
            <br>
            <a href="https://github.com/ZHANG1023/FLNeRF">video</a>
            /
            <a href="https://arxiv.org/abs/2211.11202">arXiv</a>
          </td>
        </tr>
      </tbody>
    </table>

          
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody>
        <tr>
          <td>
            <h2>Teaching</h2>
          </td>
        </tr>
      </tbody>
    </table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='CS231A_cover'>
                <img src="CS231A_cover.png" style="width:100%;">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://web.stanford.edu/class/cs231a/">
              <span class="papertitle">Stanford CS231A Computer Vision, From 3D Perception to 3D Reconstruction and beyond</span>
            </a>
            <br>
            Spring 2024
            <br>
            Teaching Assistant
            <br>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              <a href="https://github.com/jonbarron/jonbarron_website">Website Template</a>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
